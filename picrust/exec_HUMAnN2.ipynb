{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "142行目「os.system(cmd)」をコメントアウト. 意味のない繰り返しだったため."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anacondaからpythonを入手した場合以下が必要（KernelからRの設定方法）：  \n",
    "conda install -c r r-modeltools  \n",
    "conda install -c r r-mvtnorm  \n",
    "conda install -c r r-coin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11行目「python = '~'」をコメントアウト."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29行目 ref = reflist[0]　よりreflist選択可能に"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## micca is required. pip install micca ##\n",
    "\n",
    "import os, glob, itertools\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### directories ####\n",
    "proj_name = 'PRJEB9524'\n",
    "input_dir = '/Volumes/BUFFALO_4T/tanamai/16S/PRJEB9524/'\n",
    "output_dir = input_dir\n",
    "#python = '/System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python'\n",
    "keggc = '/Users/petadimensionlab/ws/apps/16S/HUMAnN2/HUMAnN1-data/keggc'\n",
    "LEfSe = '/Users/petadimensionlab/ws/apps/16S/LEfSe/'\n",
    "graphlan = '/Users/petadimensionlab/ws/apps/16S/graphlan/'\n",
    "\n",
    "# GreenGenes #\n",
    "gg97fasta = '/Users/petadimensionlab/ws/ref/gg_13_5_otus/rep_set/97_otus.fasta'\n",
    "gg97tax = '/Users/petadimensionlab/ws/ref/gg_13_5_otus/taxonomy/97_otu_taxonomy.txt'\n",
    "# Silva #\n",
    "silva_fasta = '/Users/petadimensionlab/ws/ref/silva_128/rep_set/97_otus_16S.fasta'\n",
    "silva_tax = '/Users/petadimensionlab/ws/ref/silva_128/taxonomy/consensus_taxonomy_all_levels.txt'\n",
    "# RDP #\n",
    "rdp_fasta = '/Users/petadimensionlab/ws/ref/trainset16_022016.rdp/trainset16_022016.rdp.fasta'\n",
    "rdp_tax = '/Users/petadimensionlab/ws/ref/trainset16_022016.rdp/trainset16_022016.rdp.tax'\n",
    "class_def = os.path.join(input_dir,'class_def.txt')\n",
    "\n",
    "fastalist = { 'gg':gg97fasta,'silva':silva_fasta,'rdp':rdp_fasta }\n",
    "taxlist = { 'gg':gg97tax,'silva':silva_tax,'rdp':rdp_tax }\n",
    "header = { 'gg':'gg','silva':'silva','rdp':'rdp' }\n",
    "\n",
    "reflist = ['gg','silva','rdp']\n",
    "ref = reflist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_eps = 'yes'\n",
    "is_convert_biom = 'no'\n",
    "is_micca2picrust = 'yes'\n",
    "is_exec_picrust = 'no'\n",
    "is_exec_HUMAnN2 = 'no'\n",
    "is_exec_LEfSe = 'no'\n",
    "is_exec_graphlan = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_dir = os.path.join(input_dir,'tmp')\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "tmp2_dir = os.path.join(tmp_dir,'tmp2')\n",
    "if not os.path.exists(tmp2_dir):\n",
    "    os.makedirs(tmp2_dir)\n",
    "output_dir = os.path.join(input_dir,'output')\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readtable(input_fn):\n",
    "    \"\"\"Read OTU/Taxa tables.\"\"\"\n",
    "    table = pd.read_csv(input_fn, sep='\\t', index_col=0)\n",
    "    # cast index into string\n",
    "    table.index = [str(elem) for elem in table.index]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## modified to python 3, see for the error and a way to repair ##\n",
    "## https://stackoverflow.com/questions/5237611/itertools-cycle-next ##\n",
    "\n",
    "def plotbars(input_fn, output_fn, raw=False, topn=12, xticklabelsize=8, fmt=\"png\"):\n",
    "    \"\"\"plt.gcf().canvas.get_supported_filetypes() \"\"\"\n",
    "    table = readtable(input_fn)\n",
    "    # if raw is False, plot relative abundances\n",
    "    if not raw:\n",
    "        table = table / table.sum(axis=0)\n",
    "\n",
    "    if topn > table.shape[0]:\n",
    "        topn = table.shape[0]\n",
    "    # sort by taxa abundances in decreasing order\n",
    "    taxsum = table.sum(axis=1)\n",
    "    taxsum.sort_values(ascending=False, inplace=True)\n",
    "    table = table.reindex(taxsum.index)\n",
    "    # sort by sample names\n",
    "    table.sort_index(axis=1, inplace=True)\n",
    "    # colors, hatches and edgecolors iterators\n",
    "    ncolors = 12\n",
    "    colors = [plt.cm.Paired(i) for i in np.linspace(0, 1, ncolors)]\n",
    "    edgecolors = ['k', 'w']\n",
    "    hatches = [None]*ncolors + ['////']*ncolors + ['xxxx']*ncolors\n",
    "    itercolors = itertools.cycle(colors)\n",
    "    iterhatches = itertools.cycle(hatches)\n",
    "    iteredgecolors = itertools.cycle(edgecolors)\n",
    "    # custom rc. \"svg.fonttype: none\" corrects the conversion of text in PDF\n",
    "    # and SVG files\n",
    "    rc = {\"svg.fonttype\": \"none\"}\n",
    "    with plt.rc_context(rc=rc):\n",
    "        fig = plt.figure(1)\n",
    "        ax = plt.subplot(111)\n",
    "        bars, bottom  = [], 0\n",
    "        for i in range(topn):\n",
    "            #bar = plt.bar(np.arange(table.shape[1])+0.1,table.iloc[i],bottom=bottom,linewidth=0,color=itercolors.next(),hatch=iterhatches.next(),edgecolor=iteredgecolors.next())\n",
    "            bar = plt.bar(np.arange(table.shape[1])+0.1,table.iloc[i],bottom=bottom,linewidth=0,color=next(itercolors),hatch=next(iterhatches),edgecolor=next(iteredgecolors))\n",
    "            bars.append(bar)\n",
    "            bottom = table.iloc[0:i+1].sum(axis=0)\n",
    "        lgd = ax.legend(bars,list(table.index),loc='upper center',frameon=False,bbox_to_anchor=(0.5,-0.15),fontsize=8)\n",
    "        ax.set_xticks(np.arange(table.shape[1])+0.5)\n",
    "        ax.set_xticklabels(list(table.columns), rotation=90,horizontalalignment='center', size=xticklabelsize)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        plt.xlabel(\"Sample\")\n",
    "        plt.ylabel(\"Abundance\")\n",
    "        plt.xlim((0.0,table.shape[1]))\n",
    "        if not raw:\n",
    "            plt.ylim((0.0,1.0))\n",
    "        fig.savefig(output_fn,bbox_extra_artists=(lgd,),dpi=300,bbox_inches='tight',format=fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_biom(input_biom):\n",
    "    otu_table = os.path.join(tmp_dir,proj_name+'_otutab.txt')\n",
    "    converted_biom = os.path.join(output_dir,proj_name+'_converted.biom')\n",
    "    cmd = 'biom convert --table-type=\\\"OTU table\\\" -i %s -o %s --to-tsv --header-key taxonomy' % (input_biom,otu_table)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    cmd = 'biom convert -i %s -o %s --to-json --process-obs-metadata taxonomy' % (otu_table,converted_biom)\n",
    "    print (cmd)\n",
    "    os.system(cmd)\n",
    "    #cmd = 'biom validate-table -i %s' % (converted_biom)\n",
    "    #os.system(cmd)\n",
    "    return converted_biom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def micca2picrust(otutable=\"header[ref]+'otu.txt'\"):\n",
    "    ## aggregate duplicated OTU IDs ##\n",
    "    cmd = 'R CMD BATCH --no-save --no-restore aggregate_duplicated_IDs.R'\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## get a summary statistics of an OTU-table ##\n",
    "    #cmd = 'micca tablestats -i %sggotu_unique.txt -o %s/tablestats' % (input_dir,output_dir)\n",
    "    cmd = 'micca tablestats -i %s%sotu_unique.txt -o %s/tablestats'  % (input_dir,header[ref],output_dir)\n",
    "    os.system(cmd)\n",
    "    ## get a minimum value of read depth to rarefy the OTU-table\n",
    "    cmd = 'cat %s/tablestats/tablestats_samplesumm.txt > %s/statsummary.txt' % (output_dir,output_dir)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## extract the minimum value ##\n",
    "    rfn = os.path.join(output_dir,'statsummary.txt')\n",
    "    fr = open(rfn,'r').readlines()\n",
    "    depths = []\n",
    "    fr.pop(0)\n",
    "    for line in fr:\n",
    "        tmp = line.split('\\t')\n",
    "        depths.append(int(tmp[1]))\n",
    "    minval = min(depths)\n",
    "    ## rarefy the OTU-table ##\n",
    "    #cmd = 'micca tablerare -i %s/ggotu_unique.txt -o %s/otutable_rare.txt -d %d' % (input_dir,output_dir,minval)\n",
    "    cmd = 'micca tablerare -i %s/%sotu_unique.txt -o %s/otutable_rare.txt -d %d' % (input_dir,header[ref],output_dir,minval)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## taxonomic composition ##\n",
    "    cmd = 'micca tabletotax -i %s/otutable_rare.txt -t %s -o %s/taxtables' % (output_dir,taxlist[ref],output_dir) \n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Taxonomic composition bar plot ##\n",
    "    for i in range(1,8):\n",
    "        if is_eps=='yes':\n",
    "            inputfile = '%s/taxtables/taxtable%d.txt' % (output_dir,i)\n",
    "            outputfile = '%s/taxtables/taxtable%d.eps' % (output_dir,i)\n",
    "            plotbars(inputfile,outputfile,fmt='eps')\n",
    "            #cmd = 'micca tablebar -i %s/taxtables/taxtable%d.txt -f eps -o taxtables/taxtable%d.eps' % (i,output_dir,i)\n",
    "        else:\n",
    "            inputfile = '%s/taxtables/taxtable%d.txt' % (output_dir,i)\n",
    "            outputfile = '%s/taxtables/taxtable%d.png' % (output_dir,i)\n",
    "            plotbars(inputfile,outputfile,fmt='eps')\n",
    "            #cmd = 'micca tablebar -i taxtables/taxtable%d.txt -o taxtables/taxtable%d.png' % (i,i)\n",
    "        #print (cmd)\n",
    "        #os.system(cmd)\n",
    "    ## create an picrust-suited biom file ##\n",
    "    converted_biom = os.path.join(output_dir,proj_name+'_converted.biom')\n",
    "    cmd = 'micca tobiom -i %s/otutable_rare.txt -o %s' % (output_dir,converted_biom)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    return converted_biom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exec_picrust(converted_biom):\n",
    "    normalized_biom = os.path.join(tmp_dir,proj_name+'_normalized.biom')\n",
    "    premetagen_output = os.path.join(output_dir,proj_name+'_predicted_metagenomes.biom')\n",
    "    catfun_output = os.path.join(output_dir,proj_name+'_catfun_KEGG_L3.txt')\n",
    "    cmd = 'python /home/user/anaconda2/lib/python2.7/site-packages/PICRUSt-1.1.0-py2.7.egg/EGG-INFO/scripts/normalize_by_copy_number.py -i %s -o %s' % (converted_biom,normalized_biom)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    cmd = 'python /home/user/anaconda2/lib/python2.7/site-packages/PICRUSt-1.1.0-py2.7.egg/EGG-INFO/scripts/predict_metagenomes.py -i %s -o %s' % (normalized_biom,premetagen_output)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    cmd = 'python /home/user/anaconda2/lib/python2.7/site-packages/PICRUSt-1.1.0-py2.7.egg/EGG-INFO/scripts/categorize_by_function.py -i %s -f -c KEGG_Pathways -l 3 -o %s' % (premetagen_output,catfun_output)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    picrust_outputs = [premetagen_output,catfun_output]\n",
    "    return picrust_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exec_HUMAnN2(picrust_output):\n",
    "    ## split a unified biom file into per-project biom files ##\n",
    "    cmd = '/home/user/anaconda2/bin/humann2_split_table --input %s --output %s' % (picrust_output,tmp2_dir)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## run HuMAnN2 ##\n",
    "    os.chdir(tmp2_dir)\n",
    "    bioms = glob.glob('*.biom')\n",
    "    print (bioms)\n",
    "    for biom in bioms:\n",
    "        cmd = '/home/user/anaconda2/bin/humann2 --input %s --output %s --pathways-database %s' % (biom,tmp_dir,keggc)\n",
    "        #print (cmd)\n",
    "        os.system(cmd)\n",
    "    os.chdir(input_dir)\n",
    "    ## merge HUMAnN2 output ##\n",
    "    abdtmp1 = os.path.join(tmp_dir,proj_name+'_abdtmp1.txt')\n",
    "    cmd = '/home/user/anaconda2/bin/humann2_join_tables --input %s --output %s --file_name pathabundance' % (tmp_dir,abdtmp1)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Remove _Abundance ##\n",
    "    abdtmp2 = os.path.join(tmp_dir,proj_name+'_abdtmp2.txt')\n",
    "    cmd = 'sed \"s/_Abundance//g\" %s > %s' % (abdtmp1,abdtmp2)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Add full names to the KEGG pathway identifiers ##\n",
    "    abd = os.path.join(output_dir,proj_name+'_abundance.txt')\n",
    "    cmd = '/home/user/anaconda2/bin/humann2_rename_table -i %s -o %s -n kegg-pathway --simplify' % (abdtmp2,abd)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Normalize the table into relative abundances ##\n",
    "    abdrel = os.path.join(output_dir,proj_name+'_abundance_relative.txt')\n",
    "    cmd = '/home/user/anaconda2/bin/humann2_renorm_table -i %s -o %s --units relab' % (abd,abdrel)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## merge HUMAnN2 output ##\n",
    "    covtmp1 = os.path.join(tmp_dir,proj_name+'_covtmp1.txt')\n",
    "    cmd = '/home/user/anaconda2/bin/humann2_join_tables --input %s --output %s --file_name pathcoverage' % (tmp_dir,covtmp1)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Remove _Coverage ##\n",
    "    covtmp2 = os.path.join(tmp_dir,proj_name+'_covtmp2.txt')\n",
    "    cmd = 'sed \"s/_Coverage//g\" %s > %s' % (covtmp1,covtmp2)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Add full names to the KEGG pathway identifiers ##\n",
    "    cov = os.path.join(output_dir,proj_name+'_coverage.txt')\n",
    "    cmd = '/home/user/anaconda2/bin/humann2_rename_table -i %s -o %s -n kegg-pathway --simplify' % (covtmp2,cov)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Normalize the table into relative abundances ##\n",
    "    covrel = os.path.join(output_dir,proj_name+'_coverage_relative.txt')\n",
    "    cmd = '/home/user/anaconda2/bin/humann2_renorm_table -i %s -o %s --units relab' % (cov,covrel)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    HUMAnN2_outputs = [abd,abdrel,cov,covrel]\n",
    "    return HUMAnN2_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exec_LEfSe(HUMAnN2_output):\n",
    "    fr = open(HUMAnN2_output,'r').readlines()\n",
    "    cd = open(class_def,'r').readlines()\n",
    "    fr[0] = cd[0]\n",
    "    HUMAnN2LEfSe = os.path.join(tmp_dir,'HUMAnN2LEfSe.txt')\n",
    "    fw = open(HUMAnN2LEfSe,'w')\n",
    "    for line in fr:\n",
    "        fw.write(line)\n",
    "    fw.close()\n",
    "    ## format input file suitable to LEfSe ##\n",
    "    tmp1 = os.path.join(tmp_dir,proj_name+'_LEfSe.in')\n",
    "    cmd = 'python %s %s %s -c 1 -s -1 -u -1 -o 1000000' % (os.path.join(LEfSe,'format_input.py'),HUMAnN2LEfSe,tmp1)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## execute LEfSe ##\n",
    "    LEfSe_output = os.path.join(output_dir,proj_name+'_LEfSe.res')\n",
    "    cmd = 'python %s %s %s' % (os.path.join(LEfSe,'run_lefse.py'),tmp1,LEfSe_output)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Draw cladogram ##\n",
    "    fig_output = os.path.join(output_dir,proj_name+'_LEfSe.png')\n",
    "    cmd = 'python %s %s %s --format png' % (os.path.join(LEfSe,'plot_cladogram.py'),LEfSe_output,fig_output)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    return LEfSe_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exec_graphlan(LEfSe_output,title='\\\"Phylogenic tree\\\"'):\n",
    "    tree_file = os.path.join(output_dir,proj_name+'_tree.txt')\n",
    "    annotation_file = os.path.join(output_dir,proj_name+'_annotation.txt')\n",
    "    outtree_file = os.path.join(output_dir,proj_name+'_outtree.xml')\n",
    "    treefig_file = os.path.join(output_dir,proj_name+'_tree.png')\n",
    "    ## export to graphlan from LEfSe & HUMAnN2 ##\n",
    "    cmd = 'python %s -i %s -o %s -t %s -a %s --title %s --annotations 2,3 --external_annotations 4,5,6 --fname_row 0' % (os.path.join(graphlan,'export2graphlan/export2graphlan.py'),HUMAnN2_output,LEfSe_output,tree_file,annotation_file,title)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## execute graphlan ##\n",
    "    cmd = 'python %s --annot %s %s %s' % (os.path.join(graphlan,'graphlan_annotate.py'),annotation_file,tree_file,outtree_file)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)\n",
    "    ## Draw Tree ##\n",
    "    cmd = 'python %s --dpi 300 --size 7.0 %s %s --external_legends' % (os.path.join(graphlan,'graphlan.py'),outtree_file,treefig_file)\n",
    "    #print (cmd)\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## start analysis ##\n",
    "input_biom = os.path.join(input_dir,'input.biom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert biom file for picrust ##\n",
    "#if is_convert_biom=='yes':\n",
    "#    converted_biom = convert_biom(input_biom)\n",
    "#else:\n",
    "#    converted_biom = os.path.join(input_dir,'input.biom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Volumes/BUFFALO_4T/tanamai/16S/PRJEB9524/output/taxtables/taxtable1.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-6d5b7b879ef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## convert biom file for picrust from micca ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_micca2picrust\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mconverted_biom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmicca2picrust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motutable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mconverted_biom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'input.biom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-168-f2bf4adb5e21>\u001b[0m in \u001b[0;36mmicca2picrust\u001b[0;34m(otutable)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0minputfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/taxtables/taxtable%d.txt'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0moutputfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/taxtables/taxtable%d.eps'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mplotbars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;31m#cmd = 'micca tablebar -i %s/taxtables/taxtable%d.txt -f eps -o taxtables/taxtable%d.eps' % (i,output_dir,i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-dd9e472ca585>\u001b[0m in \u001b[0;36mplotbars\u001b[0;34m(input_fn, output_fn, raw, topn, xticklabelsize, fmt)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplotbars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabelsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"plt.gcf().canvas.get_supported_filetypes() \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# if raw is False, plot relative abundances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-165-abc41802b4d8>\u001b[0m in \u001b[0;36mreadtable\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Read OTU/Taxa tables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# cast index into string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Volumes/BUFFALO_4T/tanamai/16S/PRJEB9524/output/taxtables/taxtable1.txt' does not exist"
     ]
    }
   ],
   "source": [
    "otutable = os.path.join(input_dir,\"header[ref]+'otu.txt'\")\n",
    "## convert biom file for picrust from micca ##\n",
    "if is_micca2picrust=='yes':\n",
    "    converted_biom = micca2picrust(otutable)\n",
    "else:\n",
    "    converted_biom = os.path.join(input_dir,'input.biom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## picrust ##\n",
    "if is_exec_picrust=='yes':\n",
    "    picrust_outputs = exec_picrust(converted_biom)\n",
    "    picrust_output = picrust_outputs[0]\n",
    "else:\n",
    "    picrust_output = os.path.join(output_dir,proj_name+'_predicted_metagenomes.biom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## HUMAnN2 ##\n",
    "if is_exec_HUMAnN2=='yes':\n",
    "    HUMAnN2_outputs = exec_HUMAnN2(picrust_output)\n",
    "    HUMAnN2_output = HUMAnN2_outputs[1]\n",
    "else:\n",
    "    HUMAnN2_output = os.path.join(output_dir,proj_name+'_abundance_relative.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LEfSe ##\n",
    "if is_exec_LEfSe=='yes':\n",
    "    LEfSe_output = exec_LEfSe(HUMAnN2_output)\n",
    "else:\n",
    "    LEfSe_output = os.path.join(output_dir,proj_name+'_LEfSe.res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Graphlan ##\n",
    "if is_exec_graphlan=='yes':\n",
    "    exec_graphlan(LEfSe_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
